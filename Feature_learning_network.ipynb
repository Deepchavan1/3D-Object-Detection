{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175cde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import * \n",
    "from tensorflow.math import *\n",
    "from keras.initializers import RandomNormal\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71592998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VFE_Layer(tf.keras.layers.Layer):\n",
    " \n",
    "    def __init__(self, c_out):\n",
    "        super(VFE_Layer, self).__init__()\n",
    "        self.units = c_out//2\n",
    "        self.fcn = Dense(self.units)\n",
    "        self.relu = ReLU()\n",
    "        self.bn = BatchNormalization(trainable=True)\n",
    "\n",
    "\n",
    "    def call(self, input, mask, training=False):\n",
    "        \n",
    "        fcn_out = self.relu(self.bn(self.fcn(input), training=training))\n",
    "        \n",
    "        max_pool = MaxPool2D((2,2))(fcn_out) \n",
    "        tiled_max_pool = tf.tile(max_pool, [1,1,tf.shape(fcn_out)[2],1]) # [batch_size, max_num_voxels, max_num_pts, out_dim//2]\n",
    "        output = Concatenate()([fcn_out, tiled_max_pool], axis=-1) # [batch_size, max_num_voxels, max_num_pts, out_dim//2]\n",
    "        mask = tf.tile(mask, [1,1,1, 2*self.units])\n",
    "        \n",
    "        return tf.multiply(output, tf.cast(mask, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c293ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VFE_Block(keras.layers.Layer):\n",
    " \n",
    "    def __init__(self, vfe_out_dims, final_dim, sparse_shape):\n",
    "        super(VFE_Block, self).__init__()\n",
    "\n",
    "        self.vfe_out_dims = vfe_out_dims\n",
    "        self.final_dim = final_dim\n",
    "        self.sparse_shape = sparse_shape\n",
    "\n",
    "        self.VFEs = [VFE_Layer(dim) for dim in vfe_out_dims]\n",
    "        self.final_fcn = tf.keras.layers.Dense(self.final_dim, activation=\"relu\")\n",
    " \n",
    "\n",
    "    def call(self, input, voxel_coor_buffer, shape, training=False):\n",
    "    \n",
    "\n",
    "        vfe_out = input\n",
    "\n",
    "        # create a mask for the sparse space\n",
    "        mask = tf.not_equal(tf.reduce_max(input, axis=-1, keepdims=True), 0) # [batch_size, max_num_voxels, max_num_pts, 1]\n",
    "\n",
    "        for i, vfe in enumerate(self.VFEs):\n",
    "            vfe_out = vfe(vfe_out, mask, training=training) # [batch_size, max_num_voxels, max_num_pts, vfe_out_dims[i] ]\n",
    "\n",
    "        output = self.final_fcn(vfe_out) # [batch_size, max_num_voxels, max_num_pts, final_dim]\n",
    "        output = tf.reduce_max(output, axis=2) # [batch_size, max_num_voxels, final_dim]\n",
    "\n",
    "        # Voxels Sparse representation [batch_size, Depth, Height, Width, channels]\n",
    "        output = tf.scatter_nd(indices=voxel_coor_buffer, updates=output, shape=shape)\n",
    "\n",
    "        return tf.transpose(output, perm=[0,4,1,2,3]) #[batch_size, channels, Depth, Height, Width]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf37130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "\n",
    "__cfg__ = edict()\n",
    "\n",
    "# for dataset dir\n",
    "__cfg__.DATA_DIR = 'Kitti_Dataset/'\n",
    "__cfg__.KITTY_EVAL_SCRIPT = \"kitti_eval/launch_test.sh\"\n",
    "__cfg__.CALIB_DIR = ''\n",
    "\n",
    "# selected object\n",
    "__cfg__.DETECT_OBJECT = 'Car'  # Pedestrian/Cyclist\n",
    "__cfg__.NUM_ANCHORS_PER_CELL = 2\n",
    "\n",
    "if __cfg__.DETECT_OBJECT == 'Car':\n",
    "    __cfg__.MAX_POINT_NUMBER = 35\n",
    "    __cfg__.Z_MIN = -3\n",
    "    __cfg__.Z_MAX = 1\n",
    "    __cfg__.Y_MIN = -40\n",
    "    __cfg__.Y_MAX = 40\n",
    "    __cfg__.X_MIN = 0\n",
    "    __cfg__.X_MAX = 70.4\n",
    "    __cfg__.VOXEL_X_SIZE = 0.2\n",
    "    __cfg__.VOXEL_Y_SIZE = 0.2\n",
    "    __cfg__.VOXEL_Z_SIZE = 0.4\n",
    "    __cfg__.VOXEL_POINT_COUNT = 35\n",
    "    __cfg__.INPUT_WIDTH = int((__cfg__.X_MAX - __cfg__.X_MIN) / __cfg__.VOXEL_X_SIZE)\n",
    "    __cfg__.INPUT_HEIGHT = int((__cfg__.Y_MAX - __cfg__.Y_MIN) / __cfg__.VOXEL_Y_SIZE)\n",
    "    __cfg__.INPUT_DEPTH = int((__cfg__.Z_MAX - __cfg__.Z_MIN) / __cfg__.VOXEL_Z_SIZE)\n",
    "    __cfg__.LIDAR_COORD = [0, 40, 3]\n",
    "    __cfg__.FEATURE_RATIO = 2\n",
    "    __cfg__.FEATURE_WIDTH = int(__cfg__.INPUT_WIDTH / __cfg__.FEATURE_RATIO)\n",
    "    __cfg__.FEATURE_HEIGHT = int(__cfg__.INPUT_HEIGHT / __cfg__.FEATURE_RATIO)\n",
    "else:\n",
    "    __cfg__.MAX_POINT_NUMBER = 45\n",
    "    __cfg__.Z_MIN = -3\n",
    "    __cfg__.Z_MAX = 1\n",
    "    __cfg__.Y_MIN = -20\n",
    "    __cfg__.Y_MAX = 20\n",
    "    __cfg__.X_MIN = 0\n",
    "    __cfg__.X_MAX = 48\n",
    "    __cfg__.VOXEL_X_SIZE = 0.2\n",
    "    __cfg__.VOXEL_Y_SIZE = 0.2\n",
    "    __cfg__.VOXEL_POINT_COUNT = 45\n",
    "    __cfg__.INPUT_WIDTH = int((__cfg__.X_MAX - __cfg__.X_MIN) / __cfg__.VOXEL_X_SIZE)\n",
    "    __cfg__.INPUT_HEIGHT = int((__cfg__.Y_MAX - __cfg__.Y_MIN) / __cfg__.VOXEL_Y_SIZE)\n",
    "    __cfg__.INPUT_DEPTH = int((__cfg__.Z_MAX - __cfg__.Z_MIN) / __cfg__.VOXEL_Z_SIZE)\n",
    "    __cfg__.FEATURE_RATIO = 2\n",
    "    __cfg__.LIDAR_COORD = [0, 20, 3]\n",
    "    __cfg__.FEATURE_WIDTH = int(__cfg__.INPUT_WIDTH / __cfg__.FEATURE_RATIO)\n",
    "    __cfg__.FEATURE_HEIGHT = int(__cfg__.INPUT_HEIGHT / __cfg__.FEATURE_RATIO)\n",
    "\n",
    "\n",
    "__cfg__.SCENE_SIZE = [__cfg__.Z_MAX - __cfg__.Z_MIN, __cfg__.Y_MAX- __cfg__.Y_MIN, __cfg__.X_MAX - __cfg__.X_MIN]\n",
    "__cfg__.VOXEL_SIZE = [__cfg__.VOXEL_Z_SIZE, __cfg__.VOXEL_Y_SIZE, __cfg__.VOXEL_X_SIZE]\n",
    "__cfg__.GRID_SIZE = [int(A/B) for A,B in zip(__cfg__.SCENE_SIZE, __cfg__.VOXEL_SIZE)]\n",
    "__cfg__.MAP_SHAPE = [__cfg__.FEATURE_HEIGHT, __cfg__.FEATURE_WIDTH]\n",
    "\n",
    "__cfg__.IMG_WIDTH = 1242\n",
    "__cfg__.IMG_HEIGHT = 375\n",
    "__cfg__.IMG_CHANNEL = 3\n",
    "\n",
    "\n",
    "# set the log image scale factor\n",
    "__cfg__.BV_LOG_FACTOR = 4\n",
    "\n",
    "# For the VFE layer\n",
    "__cfg__.VFE_OUT_DIMS = [32,128]\n",
    "__cfg__.VFE_FINAl_OUT_DIM = 128\n",
    "\n",
    "# cal mean from train set\n",
    "__cfg__.MATRIX_P2 = ([[719.787081,    0.,            608.463003, 44.9538775],\n",
    "                  [0.,            719.787081,    174.545111, 0.1066855],\n",
    "                  [0.,            0.,            1.,         3.0106472e-03],\n",
    "                  [0.,            0.,            0.,         0]])\n",
    "\n",
    "# cal mean from train set\n",
    "__cfg__.MATRIX_T_VELO_2_CAM = ([\n",
    "    [7.49916597e-03, -9.99971248e-01, -8.65110297e-04, -6.71807577e-03],\n",
    "    [1.18652889e-02, 9.54520517e-04, -9.99910318e-01, -7.33152811e-02],\n",
    "    [9.99882833e-01, 7.49141178e-03, 1.18719929e-02, -2.78557062e-01],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "# cal mean from train set\n",
    "__cfg__.MATRIX_R_RECT_0 = ([\n",
    "    [0.99992475, 0.00975976, -0.00734152, 0],\n",
    "    [-0.0097913, 0.99994262, -0.00430371, 0],\n",
    "    [0.00729911, 0.0043753, 0.99996319, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "\n",
    "# Faster-RCNN/SSD Hyper params\n",
    "if __cfg__.DETECT_OBJECT == 'Car':\n",
    "    # car anchor\n",
    "    __cfg__.ANCHOR_L = 3.9\n",
    "    __cfg__.ANCHOR_W = 1.6\n",
    "    __cfg__.ANCHOR_H = 1.56\n",
    "    __cfg__.ANCHOR_Z = -1.0 - __cfg__.ANCHOR_H/2\n",
    "    __cfg__.RPN_POS_IOU = 0.6\n",
    "    __cfg__.RPN_NEG_IOU = 0.45\n",
    "\n",
    "elif __cfg__.DETECT_OBJECT == 'Pedestrian':\n",
    "    # pedestrian anchor\n",
    "    __cfg__.ANCHOR_L = 0.8\n",
    "    __cfg__.ANCHOR_W = 0.6\n",
    "    __cfg__.ANCHOR_H = 1.73\n",
    "    __cfg__.ANCHOR_Z = -0.6 - __cfg__.ANCHOR_H/2\n",
    "    __cfg__.RPN_POS_IOU = 0.5\n",
    "    __cfg__.RPN_NEG_IOU = 0.35\n",
    "\n",
    "if __cfg__.DETECT_OBJECT == 'Cyclist':\n",
    "    # cyclist anchor\n",
    "    __cfg__.ANCHOR_L = 1.76\n",
    "    __cfg__.ANCHOR_W = 0.6\n",
    "    __cfg__.ANCHOR_H = 1.73\n",
    "    __cfg__.ANCHOR_Z = -0.6 - __cfg__.ANCHOR_H/2\n",
    "    __cfg__.RPN_POS_IOU = 0.5\n",
    "    __cfg__.RPN_NEG_IOU = 0.35\n",
    "\n",
    "# for rpn nms\n",
    "__cfg__.RPN_NMS_POST_TOPK = 20\n",
    "__cfg__.RPN_NMS_THRESH = 0.1\n",
    "__cfg__.RPN_SCORE_THRESH = 0.96\n",
    "\n",
    "\n",
    "__cfg__.CORNER2CENTER_AVG = True  # average version or max version\n",
    "\n",
    "\n",
    "cfg = __cfg__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c3f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vfe_block = VFE_Block(cfg.VFE_OUT_DIMS, cfg.VFE_FINAl_OUT_DIM, cfg.GRID_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c1b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
